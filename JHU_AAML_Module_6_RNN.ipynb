{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMVzB8jb8i8AFzeq/lAJjRS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rsadaphule/jhu-aaml/blob/main/JHU_AAML_Module_6_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVT9SqCMVwUu",
        "outputId": "4a5029e9-225b-43a8-d595-c1b07b954b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive; drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_DATA = '/content/drive/My Drive/JHU/AAML/Assignments/data/surnames/'"
      ],
      "metadata": {
        "id": "brTF7VrhXTaq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.dpi\"] = 72\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "print(f'PyTorch version= {torch.__version__}')\n",
        "print(f'CUDA available= {torch.cuda.is_available()}')\n",
        "\n",
        "# Set the GPU to device 0\n",
        "Gpu = torch.device('cuda:0')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0Zj_HOYJaIN",
        "outputId": "4a5077b7-bceb-4ca6-861b-5d334f22a854"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version= 2.0.1+cu118\n",
            "CUDA available= True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    # CUDA Installation\n",
        "    print('CUDA Version')\n",
        "    !nvcc --version\n",
        "    print()\n",
        "\n",
        "    # CUDNN Installation\n",
        "    print(f'CUDNN Version: {torch.backends.cudnn.version()}')\n",
        "    print(f'Number of CUDA Devices: {torch.cuda.device_count()}')\n",
        "    print(f'Active CUDA Device: {torch.cuda.current_device()}')\n",
        "    print(f'Available devices: {torch.cuda.device_count()}, Name: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'Current CUDA device: {torch.cuda.current_device()}')"
      ],
      "metadata": {
        "id": "WUfXqIQDLzQr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PATH_DATA = '../../../EP_datasets/surnames/'\n",
        "\n",
        "# Size of the longest surname, T period\n",
        "SEQ_SIZE = 20\n",
        "\n",
        "LANGS = ('English', 'Arabic', 'Chinese', 'Czech', 'Dutch', 'French', 'German', 'Greek', 'Irish', 'Italian',\n",
        "         'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese')\n",
        "\n",
        "# Test\n",
        "#LANGS = ('English', 'Arabic', 'German', 'French', 'Scottish')\n",
        "#LANGS = ('English', 'Arabic', 'German')\n",
        "#LANGS = ('English', 'Arabic')\n",
        "\n",
        "LANGS_CAT = dict(zip(LANGS, range(len(LANGS))))"
      ],
      "metadata": {
        "id": "gYoBzJqGJnym"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir, path\n",
        "\n",
        "langs, langs_n = [], []\n",
        "for fn in sorted([_ for _ in listdir(PATH_DATA) if _.endswith('.txt')]):\n",
        "    langs +=  [path.splitext(path.basename(fn))[0]]\n",
        "\n",
        "    with open(path.join(PATH_DATA, fn), 'r', encoding=\"utf8\") as fin:\n",
        "        langs_n += [len(fin.read().splitlines())]\n",
        "\n",
        "# plot\n",
        "plt.barh(langs[::-1], langs_n[::-1], color='steelblue')\n",
        "plt.xlabel('N Sample'); plt.ylabel('Language'); plt.title('Surname Classes')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "VI2juF_yKksl",
        "outputId": "eb4e01a4-07c1-4f3e-dca5-ca78caf4345c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 460.8x345.6 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir, path\n",
        "\n",
        "# Letter index 0 is the padding value, i.e. padding to fill up the vector to SEQ_SIZE, necessary for batched\n",
        "# Note that eventually we will use torch Tensor to represent these fixed length sequences\n",
        "LetterVocabulary, LetterVocabularyIndex, Index2Voc, Sequences = {' ':0}, 1, {0:' '}, {}\n",
        "for fn in sorted([_ for _ in listdir(PATH_DATA) if _.endswith('.txt')]):\n",
        "    lang, seqs = path.splitext(path.basename(fn))[0], []\n",
        "\n",
        "    if lang not in LANGS:  # test case\n",
        "        continue\n",
        "\n",
        "    with open(path.join(PATH_DATA, fn), 'r', encoding=\"utf8\") as fin:\n",
        "        for row in fin.read().splitlines():\n",
        "            seq = np.zeros(SEQ_SIZE, dtype=np.int32)\n",
        "            for i_, letter in enumerate(row.lower()):  # Convert the surname to lower case\n",
        "#            for i_, letter in enumerate(row):\n",
        "                if i_ < SEQ_SIZE:\n",
        "                    if letter not in LetterVocabulary:\n",
        "                        LetterVocabulary[letter] = LetterVocabularyIndex\n",
        "                        Index2Voc[LetterVocabularyIndex] = letter\n",
        "                        LetterVocabularyIndex += 1\n",
        "                    seq[i_] = LetterVocabulary[letter]\n",
        "            seqs += [seq]\n",
        "    Sequences[lang] = seqs\n",
        "\n",
        "# Sanity check\n",
        "def print_names(_lang, _k):\n",
        "    print(''.join([Index2Voc[c] for c in Sequences[_lang][_k]]), Sequences[_lang][_k]) if _lang in LANGS else None\n",
        "\n",
        "# Some examples\n",
        "print_names('English', 35)\n",
        "print_names('Vietnamese', 3)\n",
        "print_names('Irish', 3)\n",
        "print_names('Arabic', 1923)\n",
        "print_names('Czech', 160)\n",
        "print_names('Chinese', 233)\n",
        "print_names('German', 1)\n",
        "print_names('Korean', 69)\n",
        "print_names('Portuguese', 4)\n",
        "print_names('Russian', 1678)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZHaTu87LAn1",
        "outputId": "844a9c68-af32-4356-dfa4-7afdc0739a91"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ainley               [ 8 14  7 16 11  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "pham                 [25  2  8 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "aodha                [ 8  3 10  2  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "maalouf              [15  8  8 16  3  4 17  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "jarzembowski         [21  8  5 13 11 15 18  3 20  9  1 14  0  0  0  0  0  0  0  0]\n",
            "lu:                  [16  4 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "abel                 [ 8 18 11 16  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "si                   [ 9 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "araújo               [ 8  5  8 39 21  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "bekovich-cherkassky  [18 11  1  3 28 14 22  2 24 22  2 11  5  1  8  9  9  1  6  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity\n",
        "N = sum([len(Sequences[_]) for _ in Sequences])\n",
        "\n",
        "T = Sequences['English'][0].shape[0]\n",
        "\n",
        "C = len(np.unique(Sequences.keys())[0])\n",
        "\n",
        "print(N, T, C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1BiRJAhLHEq",
        "outputId": "799912e7-7740-40da-d937-a0c0d3d7d946"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20074 20 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "# Pool all sequences and all languages\n",
        "Seqs = [Sequences[LANGS[_]] for _ in range(C)]\n",
        "Seqs = list(itertools.chain(*Seqs))\n",
        "\n",
        "# Number of features is the number of unique characters\n",
        "M = np.max(Seqs)  # Max sequence length\n",
        "print(f'M= {M}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq10NEIyLMZ2",
        "outputId": "29aa2886-3589-4bf7-8c62-b30ff65c4633"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M= 57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apriori class balance, i.e. inverse probability of the class\n",
        "nk = np.array([len(Sequences[LANGS[_]]) for _ in range(C)], dtype=np.float32)\n",
        "nk = (N/nk)\n",
        "nk = nk/nk.sum()\n",
        "\n",
        "# Class weights, inverse apriori probability\n",
        "WEIGHTS = torch.tensor(nk, dtype=torch.float32)\n",
        "\n",
        "print(WEIGHTS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsL3MwBNLW2o",
        "outputId": "e5a196ec-502b-471e-d746-af8af51c688b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0032, 0.0059, 0.0439, 0.0227, 0.0396, 0.0425, 0.0163, 0.0580, 0.0507,\n",
            "        0.0166, 0.0119, 0.1252, 0.0847, 0.1591, 0.0013, 0.1177, 0.0395, 0.1613])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ground truth\n",
        "y = [[_]*len(Sequences[LANGS[_]]) for _ in range(C)]\n",
        "y = np.array(list(itertools.chain(*y)))"
      ],
      "metadata": {
        "id": "jeiHdCVXLgvq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode every position of the sequence\n",
        "X = np.empty((N,M))\n",
        "n = 0\n",
        "for lang in Sequences.keys():\n",
        "    for seq in Sequences[lang]:\n",
        "        sxx = np.zeros((M,), dtype=np.float32)\n",
        "        for i_ in range(SEQ_SIZE):  # for the duration of the signal\n",
        "            if seq[i_] > 0:\n",
        "                sxx[seq[i_]-1] = 1\n",
        "        X[n] = sxx\n",
        "        n += 1"
      ],
      "metadata": {
        "id": "pNYMijkOLqb7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Borrowed from previous lectures\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "def kfold_eval_docs(_clf, _X, _y):\n",
        "    # Need indexable data structure\n",
        "    acc = []\n",
        "    kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
        "    for train_index, test_index in kf.split(_X, _y):\n",
        "        _clf.fit(_X[train_index], _y[train_index])\n",
        "        y_pred = _clf.predict(_X[test_index])\n",
        "        acc += [accuracy_score(_y[test_index], y_pred)]\n",
        "    return np.array(acc)\n",
        "\n",
        "nb = GaussianNB()\n",
        "acc = kfold_eval_docs(nb, X, y)\n",
        "print(f'Naive Bayes CV accuracy= {np.mean(acc):.3f} {chr(177)}{np.std(acc):.3f}')\n",
        "\n",
        "rf = RandomForestClassifier(n_jobs=4, n_estimators=300, max_depth=10, random_state=None, class_weight='balanced')\n",
        "acc = kfold_eval_docs(rf, X, y)\n",
        "print(f'Random Forest CV accuracy= {np.mean(acc):.3f} {chr(177)}{np.std(acc):.3f}')\n",
        "\n",
        "svm = SVC(kernel='rbf', gamma='scale', class_weight='balanced')\n",
        "acc = kfold_eval_docs(svm, StandardScaler().fit_transform(X), y)\n",
        "print(f'Support Vector Machine CV accuracy= {np.mean(acc):.3f} {chr(177)}{np.std(acc):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqYWy69nLvmt",
        "outputId": "5e07de55-f3c7-4aca-bbdb-62824b3b843d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes CV accuracy= 0.060 ±0.036\n",
            "Random Forest CV accuracy= 0.462 ±0.038\n",
            "Support Vector Machine CV accuracy= 0.418 ±0.040\n",
            "CPU times: user 8min 33s, sys: 11 s, total: 8min 44s\n",
            "Wall time: 8min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RNN Cassifier"
      ],
      "metadata": {
        "id": "IOQC_6BgL0iY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode every position of the sequence\n",
        "# List of sequence, language tuples for easy shuffling\n",
        "def get_Xy():\n",
        "    Xy = []\n",
        "    for lang in Sequences.keys():\n",
        "        for seq in Sequences[lang]:\n",
        "            T = SEQ_SIZE  # necessary for batched\n",
        "            sxx = np.zeros((T, M))\n",
        "            for i in range(T):  # for the duration of the signal\n",
        "                if seq[i] > 0:\n",
        "                    sxx[i, seq[i]-1] = 1\n",
        "            Xy += [(torch.tensor(sxx, dtype=torch.float32),\n",
        "                    torch.tensor([LANGS_CAT[lang]], dtype=torch.int64))]\n",
        "    return Xy\n",
        "\n",
        "# Helper functions\n",
        "def get_X(_Xy):\n",
        "    return [_[0] for _ in _Xy]\n",
        "\n",
        "def get_y(_Xy):\n",
        "    return [int(_[1].data[0]) for _ in _Xy]\n",
        "\n",
        "# Sanity\n",
        "Xy = get_Xy()\n",
        "print(len(Xy))\n",
        "\n",
        "# printing the confusion matrix below\n",
        "def get_cm(_y, _p):\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import pandas as pd\n",
        "\n",
        "    cm = confusion_matrix(_y, _p, labels=list(range(len(LANGS))))\n",
        "    display(pd.DataFrame(cm, index=[_[:5] for _ in LANGS], columns=[_[:5] for _ in LANGS]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVwjNuEuL2m0",
        "outputId": "e85e6fa7-27d3-4225-a02d-b1be63fa9f80"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class My_RNN(nn.Module):\n",
        "\n",
        "    def __init__(self, n_hidden, n_hid_layers=1, epochs=10, eta=0.0005, batch_size=100, weight=None, info=True):\n",
        "        \"\"\" A PyTorch neural network model based on RNN cell, batched \"\"\"\n",
        "        super(My_RNN, self).__init__()\n",
        "\n",
        "        self.n_hidden= n_hidden  # hidden layer size\n",
        "        self.n_hid_layers= n_hid_layers  # number of hidden layers\n",
        "        self.epochs= epochs  # number of learning iterations\n",
        "        self.eta= eta  # learning rate\n",
        "        self.B= batch_size  # size of training batch - 1 would not work\n",
        "        self.info= info  # debug info\n",
        "\n",
        "        self.rnn, self.outlayer = None, None\n",
        "\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        # loss function, since the last layer is nn.LogSoftmax\n",
        "        self.criterion = nn.NLLLoss(weight=weight)\n",
        "\n",
        "    def forward(self, _X, _h0):\n",
        "        output, hn = self.rnn(_X, _h0)\n",
        "        output = self.outlayer(output[:, -1, :])  # output is batched\n",
        "        output = self.softmax(output)\n",
        "        return output, hn\n",
        "\n",
        "    def init_cell(self, _M):  # Create variations of our RNN by overriding init_cell\n",
        "        dropout = 0.2 if self.n_hid_layers > 1 else 0\n",
        "        return nn.RNN(_M, self.n_hidden, self.n_hid_layers,\n",
        "                      nonlinearity='relu',\n",
        "                      bias=False, batch_first=True, dropout=dropout)\n",
        "\n",
        "    def init_hidden(self, _B):  # batch_first = True\n",
        "        return torch.zeros(self.n_hid_layers, _B, self.n_hidden).to(Gpu)  # Extra dimension - batch\n",
        "\n",
        "    def fit(self, _Xy):\n",
        "        from random import shuffle\n",
        "        import sys\n",
        "        import torch.optim as optim\n",
        "\n",
        "        M= _Xy[0][0].shape[1]  # number of features, based on batch input\n",
        "        C= np.unique([int(_[1].data[0]) for _ in _Xy]).shape[0]  # number of class labels\n",
        "\n",
        "        self.rnn = self.init_cell(M).to(Gpu)\n",
        "        self.outlayer = nn.Linear(self.n_hidden, C).to(Gpu)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=self.eta)\n",
        "\n",
        "        for e in range(self.epochs):\n",
        "            # Shuffle the input to randomly interleave classes, note that they are tuples, i.e. (x, y)\n",
        "            shuffle(_Xy)\n",
        "\n",
        "            N = len(_Xy)\n",
        "            L, totloss = 0, 0\n",
        "\n",
        "            while L < N-self.B:\n",
        "                sxx = torch.stack([_[0] for _ in _Xy[L:L+self.B]]).to(Gpu)\n",
        "                y = torch.tensor([_[1] for _ in _Xy[L:L+self.B]], dtype=torch.int64).to(Gpu)\n",
        "                output, loss = self.train_signal(sxx, y, self.B)\n",
        "\n",
        "                totloss += loss\n",
        "                L += self.B\n",
        "\n",
        "                if self.info:\n",
        "                    sys.stderr.write(f\"\\r{e+1:03d}/{self.epochs:4d} | Loss: {loss:6.2f} | \"\n",
        "                                     f\"Avg loss: {totloss/(e+1):6.2f} | {y.data.tolist()[0]}\")\n",
        "                    sys.stderr.flush()\n",
        "\n",
        "    def train_signal(self, _sxx, _y, _B):\n",
        "        h0 = self.init_hidden(_B)\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        output, hn = self.forward(_sxx, h0)\n",
        "\n",
        "        loss = self.criterion(output, _y)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return output, loss.item()\n",
        "\n",
        "    def predict(self, _sxx):  # Tensor dimensions: B x T x M\n",
        "        _sxx = torch.stack(_sxx)\n",
        "        with torch.no_grad():\n",
        "            h0 = self.init_hidden(_sxx.shape[0])  # reset the hidden layer\n",
        "            output, hn = self.forward(_sxx.to(Gpu), h0)\n",
        "\n",
        "        p_values, indices = output.max(dim=1)\n",
        "        return indices.to('cpu')\n",
        "\n",
        "\n",
        "# Info about the RNN\n",
        "print(My_RNN(10, n_hid_layers=1, eta=0.001))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVWHnIPNL6uK",
        "outputId": "cd2ce52a-2b6c-4ff5-edc9-34d7efd8f978"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My_RNN(\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            "  (criterion): NLLLoss()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "Xy = get_Xy()\n",
        "\n",
        "Acc = []\n",
        "for _ in range(1):  # Statistical variation\n",
        "\n",
        "    rnn = My_RNN(128, n_hid_layers=2, epochs=1000, eta=0.005, batch_size=2000, weight=WEIGHTS, info=True).to(Gpu)\n",
        "    rnn.fit(Xy)\n",
        "\n",
        "    y_pred = rnn.predict(get_X(Xy))\n",
        "    Acc += [np.sum(np.array(y_pred) == np.array(get_y(Xy)))/len(y_pred)]\n",
        "\n",
        "print(f'RNN reclassification Acc= {np.mean(Acc):.2f} {chr(177)}{np.std(Acc):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOhpMVgIMDe-",
        "outputId": "2a735ee7-8000-4642-8cb6-3801d96226e5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000/1000 | Loss:   0.56 | Avg loss:   0.00 | 0"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN reclassification Acc= 0.75 ±0.000\n",
            "CPU times: user 7min 2s, sys: 4.27 s, total: 7min 6s\n",
            "Wall time: 2min 47s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_cm(get_y(Xy), y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "x2HR_X6GMHXp",
        "outputId": "b3ed71e7-b8f6-433f-ef2b-acbaf2b0187d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Engli  Arabi  Chine  Czech  Dutch  Frenc  Germa  Greek  Irish  Itali  \\\n",
              "Engli   1795     27     38    131    105    269    496      7    331     49   \n",
              "Arabi      0   1938      1      1      0      0      0      0      0      5   \n",
              "Chine      0      0    237      0      0      0      0      0      0      0   \n",
              "Czech     25      0      1    378      2      3     81      0      4      6   \n",
              "Dutch      1      0      3      0    272     10      8      0      0      2   \n",
              "Frenc     21      0      2      1      0    249      1      0      1      0   \n",
              "Germa     61      1      5      6     64     32    540      0      0      6   \n",
              "Greek      0      1      0      0      0      1      0    196      0      2   \n",
              "Irish      8      0      0      0      0      1      0      0    216      0   \n",
              "Itali      7      1      4      6      1      6      0      1      0    615   \n",
              "Japan      0      8      7     11      0      0      0      4      0     24   \n",
              "Korea      0      0      7      0      0      0      0      0      0      0   \n",
              "Polis      3      0      0      1      0      2      4      0      0      1   \n",
              "Portu      0      0      0      0      0      0      0      0      0      0   \n",
              "Russi    454     47     46    691    106    140    236     48     76    186   \n",
              "Scott      5      0      1      0      0      0      0      0      1      0   \n",
              "Spani      4      0      0      4      1      9      0      0      0     14   \n",
              "Vietn      0      0      0      0      0      0      0      0      0      0   \n",
              "\n",
              "       Japan  Korea  Polis  Portu  Russi  Scott  Spani  Vietn  \n",
              "Engli     17      7      6     28     37    270     46      9  \n",
              "Arabi     53      0      1      0      0      0      1      0  \n",
              "Chine      1     15      0      0      0      0      0     15  \n",
              "Czech      3      0      9      0      1      3      3      0  \n",
              "Dutch      0      0      0      0      0      0      0      1  \n",
              "Frenc      0      0      0      0      0      0      1      1  \n",
              "Germa      1      0      1      0      0      0      3      4  \n",
              "Greek      0      0      1      2      0      0      0      0  \n",
              "Irish      0      0      0      0      0      7      0      0  \n",
              "Itali      7      0      2     13      0      0     46      0  \n",
              "Japan    928      4      2      0      2      0      0      1  \n",
              "Korea      0     75      0      0      0      0      0     12  \n",
              "Polis      1      0    127      0      0      0      0      0  \n",
              "Portu      0      0      0     74      0      0      0      0  \n",
              "Russi    227      5     53     17   6966     10     82     18  \n",
              "Scott      0      0      0      0      0     93      0      0  \n",
              "Spani      0      0      0     41      0      0    225      0  \n",
              "Vietn      0      0      0      0      0      0      0     73  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-babe9660-7d16-4d8b-a05c-a16dde4e8a2c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Engli</th>\n",
              "      <th>Arabi</th>\n",
              "      <th>Chine</th>\n",
              "      <th>Czech</th>\n",
              "      <th>Dutch</th>\n",
              "      <th>Frenc</th>\n",
              "      <th>Germa</th>\n",
              "      <th>Greek</th>\n",
              "      <th>Irish</th>\n",
              "      <th>Itali</th>\n",
              "      <th>Japan</th>\n",
              "      <th>Korea</th>\n",
              "      <th>Polis</th>\n",
              "      <th>Portu</th>\n",
              "      <th>Russi</th>\n",
              "      <th>Scott</th>\n",
              "      <th>Spani</th>\n",
              "      <th>Vietn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Engli</th>\n",
              "      <td>1795</td>\n",
              "      <td>27</td>\n",
              "      <td>38</td>\n",
              "      <td>131</td>\n",
              "      <td>105</td>\n",
              "      <td>269</td>\n",
              "      <td>496</td>\n",
              "      <td>7</td>\n",
              "      <td>331</td>\n",
              "      <td>49</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>28</td>\n",
              "      <td>37</td>\n",
              "      <td>270</td>\n",
              "      <td>46</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arabi</th>\n",
              "      <td>0</td>\n",
              "      <td>1938</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chine</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>237</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Czech</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>378</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>81</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dutch</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>272</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Frenc</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>249</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Germa</th>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>64</td>\n",
              "      <td>32</td>\n",
              "      <td>540</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Greek</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>196</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Irish</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Itali</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>615</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Japan</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>928</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Korea</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Polis</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Portu</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Russi</th>\n",
              "      <td>454</td>\n",
              "      <td>47</td>\n",
              "      <td>46</td>\n",
              "      <td>691</td>\n",
              "      <td>106</td>\n",
              "      <td>140</td>\n",
              "      <td>236</td>\n",
              "      <td>48</td>\n",
              "      <td>76</td>\n",
              "      <td>186</td>\n",
              "      <td>227</td>\n",
              "      <td>5</td>\n",
              "      <td>53</td>\n",
              "      <td>17</td>\n",
              "      <td>6966</td>\n",
              "      <td>10</td>\n",
              "      <td>82</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scott</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Spani</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>225</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vietn</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-babe9660-7d16-4d8b-a05c-a16dde4e8a2c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-babe9660-7d16-4d8b-a05c-a16dde4e8a2c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-babe9660-7d16-4d8b-a05c-a16dde4e8a2c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea29ab5a-2ead-4fe9-8675-069500680844\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea29ab5a-2ead-4fe9-8675-069500680844')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea29ab5a-2ead-4fe9-8675-069500680844 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "Xy = get_Xy()\n",
        "\n",
        "cm_y, cm_p = [], []\n",
        "\n",
        "Acc = []\n",
        "kf = StratifiedKFold(n_splits=10)\n",
        "for tr_ix, ts_ix in kf.split(np.arange(len(Xy)), get_y(Xy)):\n",
        "    rnn = My_RNN(128, n_hid_layers=2, epochs=1000, eta=0.005, batch_size=2000, weight=WEIGHTS, info=True).to(Gpu)\n",
        "\n",
        "    X_tr = [Xy[_] for _ in tr_ix]  # predict uses X and y as a tuple\n",
        "    X_ts = get_X([Xy[_] for _ in ts_ix])\n",
        "    y_ts = get_y([Xy[_] for _ in ts_ix])\n",
        "\n",
        "    rnn.fit(X_tr)\n",
        "    y_pred = rnn.predict(X_ts)\n",
        "\n",
        "    Acc += [np.sum(np.array(y_pred) == np.array(y_ts))/len(y_pred)]\n",
        "\n",
        "    cm_y += y_ts\n",
        "    cm_p += y_pred.tolist()\n",
        "\n",
        "print(f'RNN 10-fold CV Acc= {np.mean(Acc):.2f} {chr(177)}{np.std(Acc):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-xd3ggyML6l",
        "outputId": "95a70706-33e7-4a6f-869f-7b3a35bba493"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000/1000 | Loss:   1.41 | Avg loss:   0.01 | 14"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN 10-fold CV Acc= 0.57 ±0.056\n",
            "CPU times: user 1h 1min 12s, sys: 24.5 s, total: 1h 1min 36s\n",
            "Wall time: 22min 4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yXCgcVXwMM9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM classifier"
      ],
      "metadata": {
        "id": "5PnQzp0EMQ4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class My_LSTM(My_RNN):\n",
        "\n",
        "    def __init__(self, n_hidden, n_hid_layers=1, epochs=10, eta=0.0005, batch_size=100, weight=None, info=True):\n",
        "        \"\"\" A PyTorch neural network model based on LSTM RNN cell, batched \"\"\"\n",
        "        super(My_LSTM, self).__init__(n_hidden, n_hid_layers=n_hid_layers,\n",
        "                                      epochs=epochs, eta=eta, batch_size=batch_size, weight=weight, info=info)\n",
        "\n",
        "    def init_hidden(self, _B):  # batch_first = True\n",
        "        return (torch.zeros(self.n_hid_layers, _B, self.n_hidden).to(Gpu),\n",
        "                torch.zeros(self.n_hid_layers, _B, self.n_hidden).to(Gpu))\n",
        "\n",
        "    def init_cell(self, _M):  # override\n",
        "        dropout = 0.2 if self.n_hid_layers > 1 else 0\n",
        "        return nn.LSTM(_M, self.n_hidden, self.n_hid_layers,\n",
        "                       #nonlinearity='relu',\n",
        "                       bias=False, batch_first=True, dropout=dropout)\n",
        "\n",
        "# Info about the RNN\n",
        "print(My_LSTM(10, n_hid_layers=1, eta=0.001))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Grihin7cMTM6",
        "outputId": "fd006d59-e37a-45a0-bd86-1bc7d5bbcefd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My_LSTM(\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            "  (criterion): NLLLoss()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "Xy = get_Xy()\n",
        "\n",
        "Acc = []\n",
        "for _ in range(1):  # Statistical variation\n",
        "\n",
        "    rnn = My_LSTM(128, n_hid_layers=1, epochs=1000, eta=0.005, batch_size=2000, weight=WEIGHTS, info=True).to(Gpu)\n",
        "    rnn.fit(Xy)\n",
        "\n",
        "    y_pred = rnn.predict(get_X(Xy))\n",
        "    Acc += [np.sum(np.array(y_pred) == np.array(get_y(Xy)))/len(y_pred)]\n",
        "\n",
        "print(f'RNN reclassification Acc= {np.mean(Acc):.2f} {chr(177)}{np.std(Acc):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ioY0zhtMX9A",
        "outputId": "17593dc4-7c30-437f-ef90-31820d012b40"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000/1000 | Loss:   0.09 | Avg loss:   0.00 | 5"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN reclassification Acc= 0.97 ±0.000\n",
            "CPU times: user 7min 21s, sys: 3.03 s, total: 7min 24s\n",
            "Wall time: 2min 43s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_cm(get_y(Xy), y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "nJ4Bv0AsMcHI",
        "outputId": "ed7e9834-f7f9-4081-925d-f748f3db2966"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Engli  Arabi  Chine  Czech  Dutch  Frenc  Germa  Greek  Irish  Itali  \\\n",
              "Engli   3376      3      8      7     11     43     28      1     55      2   \n",
              "Arabi      0   2000      0      0      0      0      0      0      0      0   \n",
              "Chine      0      0    240      0      0      1      0      0      0      0   \n",
              "Czech      0      0      0    508      2      1      0      0      0      0   \n",
              "Dutch      0      0      2      0    290      3      0      0      0      0   \n",
              "Frenc      0      0      0      0      2    263      0      0      2      0   \n",
              "Germa      0      1      1     12     25     12    659      0      3      0   \n",
              "Greek      0      0      0      0      0      0      0    203      0      0   \n",
              "Irish      0      0      0      0      0      1      0      0    225      0   \n",
              "Itali      0      0      1      0      2      1      0      0      0    672   \n",
              "Japan      0      1      2      1      0      0      0      0      0      0   \n",
              "Korea      0      0      0      0      0      0      0      0      0      0   \n",
              "Polis      0      0      0      0      0      0      0      0      0      0   \n",
              "Portu      0      0      0      0      0      0      0      0      0      0   \n",
              "Russi     14      0      4      2      0      3     12      0      2      1   \n",
              "Scott      0      0      0      0      0      0      0      0      0      0   \n",
              "Spani      0      0      0      0      0      2      0      0      0      1   \n",
              "Vietn      0      0      0      0      0      0      0      0      0      0   \n",
              "\n",
              "       Japan  Korea  Polis  Portu  Russi  Scott  Spani  Vietn  \n",
              "Engli      0      6      4     12      2     99      9      2  \n",
              "Arabi      0      0      0      0      0      0      0      0  \n",
              "Chine      0     18      0      0      0      1      0      8  \n",
              "Czech      0      0      5      0      0      3      0      0  \n",
              "Dutch      0      0      1      0      0      0      1      0  \n",
              "Frenc      0      0      5      0      0      1      4      0  \n",
              "Germa      0      2      4      0      0      1      3      1  \n",
              "Greek      0      0      0      0      0      0      0      0  \n",
              "Irish      0      0      0      0      0      6      0      0  \n",
              "Itali      0      0      2      9      0      0     22      0  \n",
              "Japan    984      3      0      0      0      0      0      0  \n",
              "Korea      0     87      0      0      0      0      0      7  \n",
              "Polis      0      0    139      0      0      0      0      0  \n",
              "Portu      0      0      0     74      0      0      0      0  \n",
              "Russi      1      5      2      0   9354      4      1      3  \n",
              "Scott      0      0      0      0      0    100      0      0  \n",
              "Spani      0      0      1     36      0      0    258      0  \n",
              "Vietn      0      0      0      0      0      0      0     73  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-961654cc-abe5-4b85-a137-e42ed426a33f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Engli</th>\n",
              "      <th>Arabi</th>\n",
              "      <th>Chine</th>\n",
              "      <th>Czech</th>\n",
              "      <th>Dutch</th>\n",
              "      <th>Frenc</th>\n",
              "      <th>Germa</th>\n",
              "      <th>Greek</th>\n",
              "      <th>Irish</th>\n",
              "      <th>Itali</th>\n",
              "      <th>Japan</th>\n",
              "      <th>Korea</th>\n",
              "      <th>Polis</th>\n",
              "      <th>Portu</th>\n",
              "      <th>Russi</th>\n",
              "      <th>Scott</th>\n",
              "      <th>Spani</th>\n",
              "      <th>Vietn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Engli</th>\n",
              "      <td>3376</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "      <td>43</td>\n",
              "      <td>28</td>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>99</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arabi</th>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chine</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Czech</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>508</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dutch</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>290</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Frenc</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>263</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Germa</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>25</td>\n",
              "      <td>12</td>\n",
              "      <td>659</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Greek</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Irish</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>225</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Itali</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>672</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Japan</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>984</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Korea</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>87</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Polis</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>139</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Portu</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Russi</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>9354</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scott</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Spani</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>258</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vietn</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-961654cc-abe5-4b85-a137-e42ed426a33f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-961654cc-abe5-4b85-a137-e42ed426a33f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-961654cc-abe5-4b85-a137-e42ed426a33f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8607390f-349b-4e5f-8360-c64cc4f1ac0f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8607390f-349b-4e5f-8360-c64cc4f1ac0f')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8607390f-349b-4e5f-8360-c64cc4f1ac0f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' This code takes forever . Hence commneted out\n",
        "%%time\n",
        "\n",
        "Xy = get_Xy()\n",
        "\n",
        "cm_y, cm_p = [], []\n",
        "\n",
        "Acc = []\n",
        "kf = StratifiedKFold(n_splits=10)\n",
        "for tr_ix, ts_ix in kf.split(np.arange(len(Xy)), get_y(Xy)):\n",
        "    rnn = My_LSTM(128, n_hid_layers=1, epochs=1000, eta=0.005, batch_size=2000, weight=WEIGHTS, info=True).to(Gpu)\n",
        "\n",
        "    X_tr = [Xy[_] for _ in tr_ix]  # predict uses X and y as a tuple\n",
        "    X_ts = get_X([Xy[_] for _ in ts_ix])\n",
        "    y_ts = get_y([Xy[_] for _ in ts_ix])\n",
        "\n",
        "    rnn.fit(X_tr)\n",
        "    y_pred = rnn.predict(X_ts)\n",
        "\n",
        "    Acc += [np.sum(np.array(y_pred) == np.array(y_ts))/len(y_pred)]\n",
        "\n",
        "    cm_y += y_ts\n",
        "    cm_p += y_pred.tolist()\n",
        "\n",
        "print(f'RNN 10-fold CV Acc= {np.mean(Acc):.2f} {chr(177)}{np.std(Acc):.3f}')\n",
        "..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "xogYxAl6MgfZ",
        "outputId": "1e105700-0984-4d48-e8ee-7f61e9094b94"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "527/1000 | Loss:   0.10 | Avg loss:   0.00 | 0"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-2709d56d9cc7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, _Xy)\u001b[0m\n\u001b[1;32m     64\u001b[0m                     sys.stderr.write(f\"\\r{e+1:03d}/{self.epochs:4d} | Loss: {loss:6.2f} | \"\n\u001b[1;32m     65\u001b[0m                                      f\"Avg loss: {totloss/(e+1):6.2f} | {y.data.tolist()[0]}\")\n\u001b[0;32m---> 66\u001b[0;31m                     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_cm(cm_y, cm_p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "z50aMMj9MlLO",
        "outputId": "76e09526-a766-4063-d581-7dcc90405ec2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Engli  Arabi  Chine  Czech  Dutch  Frenc  Germa  Greek  Irish  Itali  \\\n",
              "Engli   1737     32     32    118     81    101    169     13    104     40   \n",
              "Arabi      0   1600      0      0      0      0      0      0      0      0   \n",
              "Chine     21      2     99      3      1      4      4      0      0      1   \n",
              "Czech     79      7      1     76      7      5     34      4      3     17   \n",
              "Dutch     81      4      5      7     46     11     45      0      3      4   \n",
              "Frenc     88      3      1      7      8     40     16      3      6      8   \n",
              "Germa    142      5      5     43     64     18    168      2      4      3   \n",
              "Greek     13      2      0      3      1      2      0    110      0      7   \n",
              "Irish     83      2      0      1      0      0      6      0     69      2   \n",
              "Itali     44     10      2      9      3      7      5     11      2    300   \n",
              "Japan     28     22     10     15      0      0      1      5      3     41   \n",
              "Korea     11      0     20      1      1      0      2      0      0      1   \n",
              "Polis      5      0      0     18      2      3      3      2      0      2   \n",
              "Portu     11      0      0      1      0      6      1      4      0     16   \n",
              "Russi    464     60     31    241     46     31    217     30     33     81   \n",
              "Scott     71      0      0      3      0      1      0      0      2      0   \n",
              "Spani     25      5      0      8      3     10      5     10      1     70   \n",
              "Vietn      5      0     20      1      1      1      2      0      2      0   \n",
              "\n",
              "       Japan  Korea  Polis  Portu  Russi  Scott  Spani  Vietn  \n",
              "Engli     18     13     12      8    241    180     25     10  \n",
              "Arabi      0      0      0      0      0      0      0      0  \n",
              "Chine      4     31      1      0     16      4      0     25  \n",
              "Czech     14      1     15      2    136      4      8      2  \n",
              "Dutch      3      0      4      0     21      0      3      0  \n",
              "Frenc      0      2      4      1     23      2      9      1  \n",
              "Germa      2      3      5      1     99      9      2      4  \n",
              "Greek      3      0      3      2     12      2      3      0  \n",
              "Irish      0      0      0      1     15      7      0      0  \n",
              "Itali     36      0      3     19     66      0     49      1  \n",
              "Japan    567      4      7      4     80      0      6      0  \n",
              "Korea      2     17      0      0      6      1      1     11  \n",
              "Polis      4      0     39      0     32      0      1      0  \n",
              "Portu      3      0      0      4      4      0     10      0  \n",
              "Russi     99     15     55      7   6068     11     30      7  \n",
              "Scott      0      0      0      0      0      2      0      1  \n",
              "Spani     14      0      3     15     21      1     47      0  \n",
              "Vietn      0      7      0      1      2      0      0     17  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f51912b7-fd70-4fb6-9862-d9d0bc58ae4a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Engli</th>\n",
              "      <th>Arabi</th>\n",
              "      <th>Chine</th>\n",
              "      <th>Czech</th>\n",
              "      <th>Dutch</th>\n",
              "      <th>Frenc</th>\n",
              "      <th>Germa</th>\n",
              "      <th>Greek</th>\n",
              "      <th>Irish</th>\n",
              "      <th>Itali</th>\n",
              "      <th>Japan</th>\n",
              "      <th>Korea</th>\n",
              "      <th>Polis</th>\n",
              "      <th>Portu</th>\n",
              "      <th>Russi</th>\n",
              "      <th>Scott</th>\n",
              "      <th>Spani</th>\n",
              "      <th>Vietn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Engli</th>\n",
              "      <td>1737</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>118</td>\n",
              "      <td>81</td>\n",
              "      <td>101</td>\n",
              "      <td>169</td>\n",
              "      <td>13</td>\n",
              "      <td>104</td>\n",
              "      <td>40</td>\n",
              "      <td>18</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>241</td>\n",
              "      <td>180</td>\n",
              "      <td>25</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arabi</th>\n",
              "      <td>0</td>\n",
              "      <td>1600</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chine</th>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>99</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Czech</th>\n",
              "      <td>79</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>76</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>34</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>136</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dutch</th>\n",
              "      <td>81</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>46</td>\n",
              "      <td>11</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Frenc</th>\n",
              "      <td>88</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>40</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Germa</th>\n",
              "      <td>142</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>43</td>\n",
              "      <td>64</td>\n",
              "      <td>18</td>\n",
              "      <td>168</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Greek</th>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Irish</th>\n",
              "      <td>83</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>69</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Itali</th>\n",
              "      <td>44</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>300</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Japan</th>\n",
              "      <td>28</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>41</td>\n",
              "      <td>567</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Korea</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Polis</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Portu</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Russi</th>\n",
              "      <td>464</td>\n",
              "      <td>60</td>\n",
              "      <td>31</td>\n",
              "      <td>241</td>\n",
              "      <td>46</td>\n",
              "      <td>31</td>\n",
              "      <td>217</td>\n",
              "      <td>30</td>\n",
              "      <td>33</td>\n",
              "      <td>81</td>\n",
              "      <td>99</td>\n",
              "      <td>15</td>\n",
              "      <td>55</td>\n",
              "      <td>7</td>\n",
              "      <td>6068</td>\n",
              "      <td>11</td>\n",
              "      <td>30</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Scott</th>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Spani</th>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>70</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Vietn</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f51912b7-fd70-4fb6-9862-d9d0bc58ae4a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f51912b7-fd70-4fb6-9862-d9d0bc58ae4a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f51912b7-fd70-4fb6-9862-d9d0bc58ae4a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eec0b0a3-d9e5-4522-b2c6-2f00ed226b20\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eec0b0a3-d9e5-4522-b2c6-2f00ed226b20')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eec0b0a3-d9e5-4522-b2c6-2f00ed226b20 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kxT0Dm1-NEv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Exercise 2. Modify the ingest-script to have the first letters as capitalized letters and re-run the regular classifiers."
      ],
      "metadata": {
        "id": "8SeNYwqWNHNS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "duNMlAmrNH7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R2zxxihHNEMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[20 pts]\n",
        "1. List three popular RNN types, then briefly compare and contrast their features and\n",
        "applications.\n",
        "\n"
      ],
      "metadata": {
        "id": "1moqMHHjMrIC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nf0emqkrNBTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. [20 pts]\n",
        "Explain why the LSTM RNN performed superbly compared to the other classifiers in the module including the regular classifiers.\n",
        "\n",
        "Ans -\n",
        "Memory Cells: LSTM units have a unique design that includes memory cells, gates (input, forget, and output gates), and a hidden state. This design allows LSTMs to store and recall information over long sequences, making them particularly effective for tasks that involve sequential data, like surnames in different languages.\n",
        "\n",
        "Handling Long-Term Dependencies: One of the main challenges with basic RNNs is the vanishing gradient problem, which makes it difficult for the RNN to learn and remember information from earlier time steps in long sequences. LSTMs are specifically designed to address this issue, allowing them to capture long-term dependencies in the data.\n",
        "\n",
        "Gating Mechanisms: The gates in the LSTM units decide what information to store, discard, or output at each time step. This selective ability helps LSTMs manage and prioritize the information flow, making them more effective in understanding the structure and patterns in sequential data.\n",
        "\n",
        "Regularization: The dropout mechanism, which can be applied between LSTM layers, helps prevent overfitting, especially when dealing with a large number of parameters.\n",
        "\n",
        "Batch Training: The code uses batch training, which can help in stabilizing the learning process and speeding up convergence. LSTMs can benefit from this, especially when trained on large datasets.\n",
        "\n",
        "Class Imbalance Handling: The code uses class weights (WEIGHTS) to handle class imbalance. This ensures that minority classes are given more importance during training, which can improve the overall classification performance.\n",
        "\n",
        "Flexibility: Neural networks, including LSTMs, have the ability to learn complex non-linear relationships. This flexibility can allow them to outperform traditional classifiers, especially when there's enough data to train on.\n",
        "\n",
        "Optimization: The use of the Adam optimizer, which adjusts the learning rate during training, can help in faster and more stable convergence.\n",
        "\n",
        "Data Representation: One-hot encoding of the sequences ensures that the input data is in a format that's suitable for neural network training. This representation can capture the nuances in the data better than some traditional feature extraction methods."
      ],
      "metadata": {
        "id": "jLSV2S_nM2jT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3f8QIJpNB31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. [20 pts]\n",
        "Build a classifier using only two languages {English and Scottish} from the surname dataset\n",
        "to distinguish between them. Report 10-fold cross validation performance.\n"
      ],
      "metadata": {
        "id": "a-WpLAOGM5xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_Xy():\n",
        "    Xy = []\n",
        "    for lang in LANGS:  # Only process the languages in LANGS\n",
        "        for seq in Sequences[lang]:\n",
        "            T = SEQ_SIZE  # necessary for batched\n",
        "            sxx = np.zeros((T, M))\n",
        "            for i in range(T):  # for the duration of the signal\n",
        "                if seq[i] > 0:\n",
        "                    sxx[i, seq[i]-1] = 1\n",
        "            Xy += [(torch.tensor(sxx, dtype=torch.float32),\n",
        "                    torch.tensor([LANGS_CAT[lang]], dtype=torch.int64))]\n",
        "    return Xy\n"
      ],
      "metadata": {
        "id": "db17oi9VaFsD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apriori class balance, i.e. inverse probability of the class for only English and Scottish\n",
        "nk = np.array([len(Sequences['English']), len(Sequences['Scottish'])], dtype=np.float32)\n",
        "N = sum(nk)\n",
        "nk = (N/nk)\n",
        "nk = nk/nk.sum()\n",
        "\n",
        "# Class weights, inverse apriori probability for only English and Scottish\n",
        "WEIGHTS = torch.tensor(nk, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "qbAP2pm0aVye"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import os\n",
        "\n",
        "# Only consider English and Scottish surnames\n",
        "LANGS = ('English', 'Scottish')\n",
        "LANGS_CAT = dict(zip(LANGS, range(len(LANGS))))\n",
        "\n",
        "\n",
        "def load_surnames_from_file(filepath):\n",
        "    with open(filepath, 'r', encoding=\"utf8\") as f:\n",
        "        return f.read().splitlines()\n",
        "\n",
        "# Assuming the dataset is in a folder named 'surnames'\n",
        "english_surnames = load_surnames_from_file(PATH_DATA + 'English.txt')\n",
        "scottish_surnames = load_surnames_from_file(PATH_DATA  + 'Scottish.txt')\n",
        "\n",
        "# Label the data: 0 for English, 1 for Scottish\n",
        "data = [(name, 0) for name in english_surnames] + [(name, 1) for name in scottish_surnames]\n",
        "\n",
        "\n",
        "#Feature Extraction\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "names, labels = zip(*data)\n",
        "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(1,3))\n",
        "X = vectorizer.fit_transform(names)\n",
        "y = labels\n",
        "\n",
        "\n",
        "#training\n",
        "Xy = get_Xy()\n",
        "\n",
        "cm_y, cm_p = [], []\n",
        "Acc = []\n",
        "\n",
        "kf = StratifiedKFold(n_splits=10)\n",
        "for tr_ix, ts_ix in kf.split(np.arange(len(Xy)), get_y(Xy)):\n",
        "    rnn = My_LSTM(128, n_hid_layers=1, epochs=1000, eta=0.005, batch_size=2000, weight=WEIGHTS, info=True).to(Gpu)\n",
        "\n",
        "    X_tr = [Xy[_] for _ in tr_ix]  # predict uses X and y as a tuple\n",
        "    X_ts = get_X([Xy[_] for _ in ts_ix])\n",
        "    y_ts = get_y([Xy[_] for _ in ts_ix])\n",
        "\n",
        "    rnn.fit(X_tr)\n",
        "    y_pred = rnn.predict(X_ts)\n",
        "\n",
        "    Acc += [np.sum(np.array(y_pred) == np.array(y_ts))/len(y_pred)]\n",
        "    cm_y += y_ts\n",
        "    cm_p += y_pred.tolist()\n",
        "\n",
        "print(f'LSTM 10-fold CV Acc= {np.mean(Acc):.2f} ± {np.std(Acc):.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xgj2TZ7lNCib",
        "outputId": "1db80093-5ec2-4366-e67e-d84b3f77e3c7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1000/1000 | Loss:   0.10 | Avg loss:   0.00 | 0"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM 10-fold CV Acc= 0.67 ± 0.179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. [40 pts]\n",
        "Determine an optimum sequence length (i.e., surname length), by finding a sweet spot\n",
        "between the run-time (due to the sequence length) and the classification performance."
      ],
      "metadata": {
        "id": "8rDqCMMhM7mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Load surnames from file\n",
        "def load_surnames_from_file(filepath):\n",
        "    with open(filepath, 'r', encoding=\"utf8\") as f:\n",
        "        return f.read().splitlines()\n",
        "\n",
        "# Only consider English and Scottish surnames\n",
        "LANGS = ('English', 'Scottish')\n",
        "LANGS_CAT = dict(zip(LANGS, range(len(LANGS))))\n",
        "\n",
        "# Assuming the dataset is in a folder named 'surnames'\n",
        "english_surnames = load_surnames_from_file(PATH_DATA + 'English.txt')\n",
        "scottish_surnames = load_surnames_from_file(PATH_DATA  + 'Scottish.txt')\n",
        "\n",
        "\n",
        "# Combine and label the data\n",
        "data = [(name, 0) for name in english_surnames] + [(name, 1) for name in scottish_surnames]\n",
        "names, labels = zip(*data)\n",
        "\n",
        "# Analyze the distribution of surname lengths\n",
        "surname_lengths = [len(name) for name in names]\n",
        "plt.hist(surname_lengths, bins=50)\n",
        "plt.xlabel('Surname Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Surname Lengths')\n",
        "plt.show()\n",
        "\n",
        "# Your existing LSTM model and data preprocessing functions go here\n",
        "# ... (e.g., My_LSTM, get_Xy, etc.)\n",
        "\n",
        "# Experiment with different sequence lengths\n",
        "sequence_lengths = list(range(5, max(surname_lengths), 5))\n",
        "performances = []\n",
        "runtimes = []\n",
        "\n",
        "for seq_len in sequence_lengths:\n",
        "    SEQ_SIZE = seq_len  # Adjust the sequence size\n",
        "\n",
        "    # Data preprocessing (adjust for the new sequence length)\n",
        "    # ... (as in the previous code)\n",
        "\n",
        "    # Train the LSTM model\n",
        "    start_time = time.time()\n",
        "\n",
        "    Xy = get_Xy()\n",
        "    rnn = My_LSTM(128, n_hid_layers=1, epochs=1000, eta=0.005, batch_size=2000, weight=WEIGHTS, info=False).to(Gpu)\n",
        "    rnn.fit(Xy)\n",
        "\n",
        "    y_pred = rnn.predict(get_X(Xy))\n",
        "    acc = np.sum(np.array(y_pred) == np.array(get_y(Xy)))/len(y_pred)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Record performance and runtime\n",
        "    performances.append(acc)\n",
        "    runtimes.append(end_time - start_time)\n",
        "\n",
        "# Plot runtime and performance against sequence lengths\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(sequence_lengths, runtimes, '-o')\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Runtime (seconds)')\n",
        "plt.title('Runtime vs. Sequence Length')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(sequence_lengths, performances, '-o')\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy vs. Sequence Length')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "p05_hteSNDLY",
        "outputId": "41b1a68f-62f8-4c6a-f13b-d5cf3ff1e313"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-d79ec0de4755>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mLANGS_CAT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLANGS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLANGS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0menglish_surnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_surnames_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'surnames/English.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mscottish_surnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_surnames_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'surnames/Scottish.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-d79ec0de4755>\u001b[0m in \u001b[0;36mload_surnames_from_file\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load surnames from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_surnames_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'surnames/English.txt'"
          ]
        }
      ]
    }
  ]
}